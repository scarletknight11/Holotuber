<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.Azure.Kinect.Sensor</name>
    </assembly>
    <members>
        <member name="T:Microsoft.Azure.Kinect.Sensor.Allocator">
            <summary>
            Manages buffer allocation.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Allocator.Singleton">
            <summary>
            Gets the Allocator.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Allocator.UseManagedAllocator">
            <summary>
            Gets or sets a value indicating whether to have the native library use the managed allocator.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Allocator.SafeCopyNativeBuffers">
            <summary>
            Gets or sets a value indicating whether to make a safe copy of native buffers.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Allocator.RegisterForDisposal(System.IDisposable)">
             <summary>
             Register the object for disposal when the CLR shuts down.
             </summary>
             <param name="disposable">Object to dispose before native hooks are disconnected.</param>
             <remarks>
             When the CLR shuts down, native callbacks in to the CLR result in an application crash. The allocator free method
             is a native callback to the managed layer that is called whenever the hooked native API needs to free memory.
            
             To avoid this callback after the CLR shuts down, the native library must be completly cleaned up prior CLR shutdown.
            
             Any object that may hold references to the native library (and will therefore generate native to manged callbacks when it
             gets cleaned up) should register with the RegisterForDisposal method to ensure it is cleaned up in the correct order.
             during shutdown.
             </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Allocator.UnregisterForDisposal(System.IDisposable)">
            <summary>
            Unregister the object for disposal.
            </summary>
            <param name="disposable">Object to unregister.</param>
            <remarks>
            This does not unhook the native allocator, but only unregisters the object for
            disposal.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Allocator.GetManagedAllocatedMemory(System.IntPtr,System.Int64)">
             <summary>
             Get a Memory reference to the managed memory that was used by the hooked native
             allocator.
             </summary>
             <param name="address">Native address of the memory.</param>
             <param name="size">Size of the memory region.</param>
             <returns>Reference to the memory, or an empty memory reference.</returns>
             <remarks>
             If the address originally came from a managed array that was provided to the native
             API through the allocator hook, this function will return a Memory reference to the managed
             memory. Since this is a reference to the managed memory and not the native pointer, it
             is safe and not subject to use after free bugs.
            
             The address and size do not need to reference the exact pointer provided to the native layer
             by the allocator, but can refer to any region in the allocated memory.
             </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Allocator.GetBufferCache(System.IntPtr,System.Int32)">
            <summary>
            Get a managed array to cache the contents of a native buffer.
            </summary>
            <param name="nativeAddress">Native buffer to mirror.</param>
            <param name="size">Size of the native memory.</param>
            <returns>A managed array populated with the content of the native buffer.</returns>
            <remarks>Multiple callers asking for the same address will get the same buffer.
            When done with the buffer the caller must call <seealso cref="M:Microsoft.Azure.Kinect.Sensor.Allocator.ReturnBufferCache(System.IntPtr)"/>.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Allocator.ReturnBufferCache(System.IntPtr)">
            <summary>
            Return the buffer cache.
            </summary>
            <param name="nativeAddress">Address of the native buffer.</param>
            <remarks>Must be called exactly once for each buffer provided by <see cref="M:Microsoft.Azure.Kinect.Sensor.Allocator.GetBufferCache(System.IntPtr,System.Int32)"/>.</remarks>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.AzureKinectException">
            <summary>
            Represents errors that occur when interactive with the Azure Kinect Sensor SDK.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectException.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectException"/> class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectException.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectException"/> class with a specified error message.
            </summary>
            <param name="message">The message that describes the error.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectException.#ctor(System.String,System.Exception)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectException"/> class with a specified error message and a reference to the inner exception that is the cause of this exception.
            </summary>
            <param name="message">The error message that explains the reason for the exception.</param>
            <param name="innerException">The exception that is the cause of the current exception, or a null reference (Nothing in Visual Basic) if no inner exception is specified.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectException.#ctor(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectException"/> class with serialized data.
            </summary>
            <param name="info">The <see cref="T:System.Runtime.Serialization.SerializationInfo"/> that holds the serialized object data about the exception being thrown.</param>
            <param name="context">The <see cref="T:System.Runtime.Serialization.StreamingContext"/>System.Runtime.Serialization.StreamingContext that contains contextual information about the source or destination.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectException.ThrowIfNotSuccess(Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_result_t)">
            <summary>
            Throws an <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectException"/> if the result is not <see cref="F:Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_result_t.K4A_RESULT_SUCCEEDED"/>.
            </summary>
            <param name="result">The result to check.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectException.ThrowIfNotSuccess(Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_wait_result_t)">
            <summary>
            Throws an <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectException"/> if the result is not <see cref="F:Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_wait_result_t.K4A_WAIT_RESULT_SUCCEEDED"/>.
            </summary>
            <param name="result">The result to check.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectException.ThrowIfNotSuccess(Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_buffer_result_t)">
            <summary>
            Throws an <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectException"/> if the result is not <see cref="F:Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_buffer_result_t.K4A_BUFFER_RESULT_SUCCEEDED"/>.
            </summary>
            <param name="result">The result to check.</param>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryCast`2">
            <summary>
            Helper to cast from one Memory type to another.
            </summary>
            <typeparam name="TFrom">Element type of the original Memory.</typeparam>
            <typeparam name="TTo">Element type of the new Memory.</typeparam>
            <remarks>
            This type does not take ownership of the Memory, so Dispose does nothing.
            The resultant Memory object derived from this type has the same useful lifetime as
            the source Memory object.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryCast`2.#ctor(System.Memory{`0})">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryCast`2"/> class.
            </summary>
            <param name="memory">Memory object to cast.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryCast`2.GetSpan">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryCast`2.Pin(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryCast`2.Unpin">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryCast`2.Dispose(System.Boolean)">
            <inheritdoc/>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryManager">
            <summary>
            Manages the native memory allocated by the Azure Kinect SDK.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryManager.#ctor(Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryManager"/> class.
            </summary>
            <param name="image">Image with native memory.</param>
            <remarks>
            Constructs a new MemoryManager representing the native memory backing an Image.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryManager.GetSpan">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryManager.Pin(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryManager.Unpin">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.AzureKinectMemoryManager.Dispose(System.Boolean)">
            <inheritdoc/>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.BGRA">
            <summary>
            Describes a pixel of color in terms of blue, green, red, and alpha channels.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.BGRA.#ctor(System.Byte,System.Byte,System.Byte,System.Byte)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure.
            </summary>
            <param name="blue">The blue channel value of the color.</param>
            <param name="green">The green channel value of the color.</param>
            <param name="red">The red channel value of the color.</param>
            <param name="alpha">The alpha channel value of the color.</param>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.BGRA.A">
            <summary>
            Gets or sets the BGRA alpha channel value of the color.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.BGRA.R">
            <summary>
            Gets or sets the BGRA red channel value of the color.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.BGRA.G">
            <summary>
            Gets or sets the BGRA green channel value of the color.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.BGRA.B">
            <summary>
            Gets or sets the BGRA blue channel value of the color.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.BGRA.Value">
            <summary>
            Gets or sets the combined BGRA value of the color.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.BGRA.op_Equality(Microsoft.Azure.Kinect.Sensor.BGRA,Microsoft.Azure.Kinect.Sensor.BGRA)">
            <summary>
            Tests whether two <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structures are identical.
            </summary>
            <param name="bgra1">The first <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure to compare.</param>
            <param name="bgra2">The second <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure to compare.</param>
            <returns><c>true</c> if <paramref name="bgra1"/> and <paramref name="bgra2"/> are exactly identical; otherwise, <c>flase</c>.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.BGRA.op_Inequality(Microsoft.Azure.Kinect.Sensor.BGRA,Microsoft.Azure.Kinect.Sensor.BGRA)">
            <summary>
            Tests whether two <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structures are not identical.
            </summary>
            <param name="bgra1">The first <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure to compare.</param>
            <param name="bgra2">The second <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure to compare.</param>
            <returns><c>true</c> if <paramref name="bgra1"/> and <paramref name="bgra2"/> are note equal; otherwise, <c>flase</c>.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.BGRA.Equals(System.Object)">
            <summary>
            Tests whether the specified object is a <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure and is equivalent to this <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/>.
            </summary>
            <param name="obj">The object to compare to this <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure.</param>
            <returns><c>true</c> if the specified object is a <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure and is identical to the current <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure; otherwise, <c>flase</c>.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.BGRA.Equals(Microsoft.Azure.Kinect.Sensor.BGRA)">
            <summary>
            Tests whether the specified <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure is equivalent to this <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/>.
            </summary>
            <param name="other">The <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure to compare to the current <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure.</param>
            <returns><c>true</c> if the specified <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure is identical to the current <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure; otherwise, <c>flase</c>.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.BGRA.GetHashCode">
            <summary>
            Gets a hash code for this <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure.
            </summary>
            <returns>A hash code for this <see cref="T:Microsoft.Azure.Kinect.Sensor.BGRA"/> structure.</returns>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.Capture">
            <summary>
            A set of images captured in sync.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Capture"/> class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.#ctor(Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_capture_t)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Capture"/> class.
            </summary>
            <param name="handle">Native handle of the Capture.</param>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Capture.Color">
             <summary>
             Gets or sets the color image of this capture.
             </summary>
             <remarks>
             Images assigned to this capture are owned by the Capture. When the Capture is disposed, the
             Color Image will be disposed.
            
             By setting the Color image on a Capture, the Capture takes ownership and the Capture will
             dispose the Image when the Capture is disposed.
            
             To get an instance of an Image that lives longer than the capture, call Image.Reference().
             </remarks>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Capture.Depth">
             <summary>
             Gets or sets the depth image of this capture.
             </summary>
             <remarks>
             Images assigned to this capture are owned by the Capture. When the Capture is disposed, the
             Depth Image will be disposed.
            
             By setting the Depth image on a Capture, the Capture takes ownership and the Capture will
             dispose the Image when the Capture is disposed.
            
             To get an instance of an Image that lives longer than the capture, call Image.Reference().
             </remarks>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Capture.IR">
             <summary>
             Gets or sets the IR image of this capture.
             </summary>
             <remarks>
             Images assigned to this capture are owned by the Capture. When the Capture is disposed, the
             IR Image will be disposed.
            
             By setting the IR image on a Capture, the Capture takes ownership and the Capture will
             dispose the Image when the Capture is disposed.
            
             To get an instance of an Image that lives longer than the capture, call Image.Reference().
             </remarks>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Capture.Temperature">
            <summary>
            Gets or sets the device temperature at the time of the capture.
            </summary>
            <remarks>
            Temperature is represented in degrees Celsius.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.Reference">
            <summary>
            Creates a duplicate reference to the same Capture.
            </summary>
            <returns>A new Capture object representing the same data.</returns>
            <remarks>Creating a reference to the same capture does not copy the capture,
            or the image data stored in the capture, but creates a new managed object representing
            the same capture data. Each object must be independently disposed. The lifetime of the
            underlying capture data will be equal or greater than all of the referenced Capture objects.</remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.DangerousGetHandle">
            <summary>
            Gets the native handle.
            </summary>
            <returns>The native handle that is wrapped by this capture.</returns>
            <remarks>The function is dangerous because there is no guarantee that the
            handle will not be disposed once it is retrieved. This should only be called
            by code that can ensure that the Capture object will not be disposed on another
            thread.</remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.NativeEquals(Microsoft.Azure.Kinect.Sensor.Capture)">
            <summary>
            Checks two captures to determine if they represent the same native capture object.
            </summary>
            <param name="other">Another Capture to compare against.</param>
            <returns>true if the Captures represent the same native k4a_capture_t.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.Dispose(System.Boolean)">
            <summary>
            Handle the disposing of the object.
            </summary>
            <param name="disposing">true when called by Dispose(), false when called by the finalizer.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.UpdateImageWrapperAndDisposePrevious(System.Func{Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_capture_t,Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_image_t},Microsoft.Azure.Kinect.Sensor.Image@)">
            <summary>
            Retrieves a native image handle from the native API.
            </summary>
            <param name="nativeMethod">Native method to retrieve the image.</param>
            <param name="cachedImage">A cached instance of the Image that we return to callers. (Callers may dispose this image, although they shouldn't).</param>
            <remarks>
            If this is the first time calling the property, we construct a new wrapper.
            If the handle is for an Image we have already constructed a wrapper for, we return the existing wrapper.
            If the handle is for a different Image, we construct a new wrapper and dispose the old one.
            If existing wrapper has been disposed, we throw an exception.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Capture.SetImageWrapperAndDisposePrevious(System.Action{Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_capture_t,Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_image_t},Microsoft.Azure.Kinect.Sensor.Image@,Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Sets the image wrapper provided to a property.
            </summary>
            <param name="nativeMethod">Native set method.</param>
            <param name="cachedImage">Refrence to the cached image wrapper used by this class.</param>
            <param name="value">Value to assign the image wrapper to.</param>
            <remarks>
            This function takes ownership of the wrapper and stores it in the class. If there was
            a previous wrapper owned by the class, this function will dispose it.
            </remarks>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.ColorControlCommand">
            <summary>
            Color sensor control commands. 
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.ExposureTimeAbsolute">
             <summary>
             Exposure time setting.
             </summary>
             <remarks>
             May be set to Auto or Manual.
            
             Exposure time is measured in microseconds.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.Brightness">
             <summary>
             Brightness setting.
             </summary>
             <remarks>
             May only be set to Manual.
            
             The valid range is 0 to 255. The default value is 128.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.Contrast">
            <summary>
            Contrast setting.
            </summary>
            <remarks>
            May only be set to Manual.
            </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.Saturation">
            <summary>
            Saturation setting.
            </summary>
            <remarks>
            May only be set to Manual.</remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.Sharpness">
            <summary>
            Sharpness setting.
            </summary>
            <remarks>
            May only be set to Manual.
            </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.Whitebalance">
             <summary>
             White balance setting.
             </summary>
             <remarks>
             May be set to Auto or Manual.
            
             The unit is degrees Kelvin. The setting must be set to a value evenly divisible by 10 degrees.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.BacklightCompensation">
             <summary>
             Backlight compensation setting.
             </summary>
             <remarks>
             May only be set to Manual.
            
             Value of 0 means backlight compensation is disabled.
             Value of 1 means backlight compensation is enabled.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.Gain">
            <summary>
            Gain setting.
            </summary>
            <remarks>
            May only be set to Manual.
            </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlCommand.PowerlineFrequency">
             <summary>
             Powerline frequency setting.
             </summary>
             <remarks>
             May only be set to Manual.
            
             Value of 1 sets the powerline compensation to 50 Hz.
             Value of 2 sets the powerline compensation to 60 Hz.
             </remarks>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.ColorControlMode">
            <summary>
            Color sensor control mode. 
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlMode.Auto">
            <summary>
            Set the associated <see cref="T:Microsoft.Azure.Kinect.Sensor.ColorControlCommand"/> to Auto.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorControlMode.Manual">
            <summary>
            Set the associated <see cref="T:Microsoft.Azure.Kinect.Sensor.ColorControlCommand"/> to Manual.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.ColorResolution">
            <summary>
            Color sensor resolutions.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorResolution.Off">
            <summary>
            Color camera will be turned off with this setting.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorResolution.R720p">
            <summary>
            1280 * 720 16:9
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorResolution.R1080p">
            <summary>
            1920 * 1080 16:9
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorResolution.R1440p">
            <summary>
            2560 * 1440 16:9
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorResolution.R1536p">
            <summary>
            2048 * 1536 4:3
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorResolution.R2160p">
            <summary>
            3840 * 2160 16:9
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ColorResolution.R3072p">
            <summary>
            4096 * 3072 4:3
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.DebugMessageEventArgs">
            <summary>
            Represents a debug message from the Azure Kinect Sensor SDK.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DebugMessageEventArgs.LogLevel">
            <summary>
            Gets or sets the log level of this debug message.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DebugMessageEventArgs.FileName">
            <summary>
            Gets or sets the file name of the source file that generated the message.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DebugMessageEventArgs.Line">
            <summary>
            Gets or sets the line number of the source file that generated the message.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DebugMessageEventArgs.Message">
            <summary>
            Gets or sets the message generated by the Azure Kinect Sensor SDK.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.DepthMode">
            <summary>
            Depth sensor capture modes.
            </summary>
            <remarks>
            See the hardware specification for additional details on the field of view, and supported frame rates for each mode.
            NFOV and WFOV denote Narrow and Wide Field Of View configurations.
            Binned modes reduce the captured camera resolution by combining adjacent sensor pixels into a bin.
            </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.DepthMode.Off">
            <summary>
            Depth sensor will be turned off with this setting.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.DepthMode.NFOV_2x2Binned">
            <summary>
            Depth and Passive IR are captured at 320x288.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.DepthMode.NFOV_Unbinned">
            <summary>
            Depth and Passive IR are captured at 640x576.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.DepthMode.WFOV_2x2Binned">
            <summary>
            Depth and Passive IR are captured at 512x512.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.DepthMode.WFOV_Unbinned">
            <summary>
            Depth and Passive IR are captured at 1024x1024.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.DepthMode.PassiveIR">
            <summary>
            Passive IR only iscaptured at 1024x1024.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.Device">
            <summary>
            Represents an Azure Kinect device.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Device.SerialNum">
            <summary>
            Gets the devices serial number.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Device.CurrentDepthMode">
            <summary>
            Gets the depth mode the device is currently set to.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Device.CurrentColorResolution">
            <summary>
            Gets the color resolution the device is currently set to.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Device.SyncInJackConnected">
            <summary>
            Gets a value indicating whether gets the Sync In jack is connected.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Device.SyncOutJackConnected">
            <summary>
            Gets a value indicating whether gets the Sync Out jack is connected.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Device.Version">
            <summary>
            Gets the hardware version of the device.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetInstalledCount">
            <summary>
            Gets the number of currently connected devices.
            </summary>
            <returns>The number of connected devices.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.Open(System.Int32)">
            <summary>
            Opens an Azure Kinect device.
            </summary>
            <param name="index">Index of the device to open if there are multiple connected.</param>
            <returns>A Device object representing that device.</returns>
            <remarks>The device will remain opened for exclusive access until the Device object is disposed.</remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetCalibration(Microsoft.Azure.Kinect.Sensor.DepthMode,Microsoft.Azure.Kinect.Sensor.ColorResolution)">
            <summary>
            Gets the calibration of the device.
            </summary>
            <param name="depthMode">Depth mode for the calibration.</param>
            <param name="colorResolution">Color camera resolution for the calibration.</param>
            <returns>Calibration object.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetCalibration">
            <summary>
            Gets the calibration of the device for the current operating mode.
            </summary>
            <returns>Calibration object.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetRawCalibration">
            <summary>
            Gets the device raw calibration data.
            </summary>
            <returns>The raw data can be stored offline for future use.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetCapture(System.TimeSpan)">
            <summary>
            Reads a sensor capture.
            </summary>
            <param name="timeout">Time to wait for a capture.</param>
            <returns>A Capture object holding image data.</returns>
            <remarks>Gets the next capture in the streamed sequence of captures from the camera. 
            If a new capture is not currently available, this function will block until the timeout is reached. 
            The SDK will buffer at least two captures worth of data before dropping the oldest capture. 
            Callers needing to capture all data need to ensure they read the data as fast as the data is being produced on average.</remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetCapture">
            <summary>
            Reads a sensor capture.
            </summary>
            <returns>A Capture object holding image data.</returns>
            <remarks>Gets the next capture in the streamed sequence of captures from the camera.
            If a new capture is not currently available, this function will block until one is available.
            The SDK will buffer at least two captures worth of data before dropping the oldest capture.
            Callers needing to capture all data need to ensure they read the data as fast as the data is being produced on average.</remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetImuSample(System.TimeSpan)">
            <summary>
            Reads an IMU sample from the device.
            </summary>
            <param name="timeout">Time to wait for an IMU sample.</param>
            <returns>The next unread IMU sample from the device.</returns>
            <remarks>Gets the next sample in the streamed sequence of IMU samples from the device.
            If a new sample is not currently available, this function will block until the timeout is reached.
            The API will buffer at least two camera capture intervals worth of samples before dropping the oldest sample. Callers needing to capture all data need to ensure they read the data as fast as the data is being produced on average.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetImuSample">
            <summary>
            Reads an IMU sample from the device.
            </summary>
            <returns>The next unread IMU sample from the device.</returns>
            <remarks>Gets the next sample in the streamed sequence of IMU samples from the device.
            If a new sample is not currently available, this function will block until one is available.
            The API will buffer at least two camera capture intervals worth of samples before dropping the oldest sample. Callers needing to capture all data need to ensure they read the data as fast as the data is being produced on average.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetColorControl(Microsoft.Azure.Kinect.Sensor.ColorControlCommand)">
            <summary>
            Get the Azure Kinect color sensor control value.
            </summary>
            <param name="command">Color sensor control command.</param>
            <returns>The value of the color control option.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.GetColorControl(Microsoft.Azure.Kinect.Sensor.ColorControlCommand,Microsoft.Azure.Kinect.Sensor.ColorControlMode@)">
            <summary>
            Get the Azure Kinect color sensor control value.
            </summary>
            <param name="command">Color sensor control command.</param>
            <param name="mode">The mode of the color control option.</param>
            <returns>The value of the color control option.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.SetColorControl(Microsoft.Azure.Kinect.Sensor.ColorControlCommand,Microsoft.Azure.Kinect.Sensor.ColorControlMode,System.Int32)">
            <summary>
            Sets the Azure Kinect color sensor control value.
            </summary>
            <param name="command">Color sensor control command.</param>
            <param name="mode">The mode of the color control option.</param>
            <param name="value">The value of the color control option.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.StartCameras(Microsoft.Azure.Kinect.Sensor.DeviceConfiguration)">
            <summary>
            Starts color and depth camera capture. 
            </summary>
            <param name="configuration">The configuration we want to run the device in.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.StopCameras">
            <summary>
            Stops the color and depth camera capture.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.StartImu">
            <summary>
            Starts the IMU sample stream.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.StopImu">
            <summary>
            Stops the IMU sample stream.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Device.Dispose(System.Boolean)">
            <summary>
            Handle the Dispose pattern.
            </summary>
            <param name="disposing">True if called by Dispose</param>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration">
            <summary>
            Represents the configuration to run an Azure Kinect device in.
            </summary>
            <remarks>
            Default initialization is the same as K4A_DEVICE_CONFIG_INIT_DISABLE_ALL.
            </remarks>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.ColorFormat">
            <summary>
            Gets or sets the image format to capture with the color camera.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.ColorResolution">
            <summary>
            Gets or sets the image resolution to capture with the color camera.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.DepthMode">
            <summary>
            Gets or sets the capture mode for the depth camera.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.CameraFPS">
            <summary>
            Gets or sets the desired frame rate for the color and depth cameras.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.SynchronizedImagesOnly">
            <summary>
            Gets or sets a value indicating whether to only return synchrnoized depth and color images.
            </summary>
            <remarks>
            If this is false, when color or depth images are dropped, the other corrisponding image will be dropped too.
            </remarks>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.DepthDelayOffColor">
            <summary>
            Gets or sets the desired delay between the capture of the color image and the capture of the depth image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.WiredSyncMode">
            <summary>
            Gets or sets the external synchronization mode.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.SuboridinateDelayOffMaster">
            <summary>
            Gets or sets the external synchrnoization timining.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.DisableStreamingIndicator">
            <summary>
            Gets or sets a value indicating whether the automatic streaming indicator light is disabled.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.DeviceConfiguration.GetNativeConfiguration">
            <summary>
            Get the equivilant native configuration structure.
            </summary>
            <returns>A k4a_device_configuration_t.</returns>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.FirmwareBuild">
            <summary>
            Firmware build type.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.FirmwareBuild.Release">
            <summary>
            Production firmware.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.FirmwareBuild.Debug">
            <summary>
            Pre-production firmeare.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.FirmwareSignature">
            <summary>
            Firmware signature type.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.FirmwareSignature.Msft">
            <summary>
            Microsoft signed firmware.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.FirmwareSignature.Test">
            <summary>
            Test signed firmware.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.FirmwareSignature.NotSigned">
            <summary>
            Unsigned firmware.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.FPS">
            <summary>
            Color and depth sensor frame rate.
            </summary>
            <remarks>
            This enumeration is used to select the desired frame rate to operate the cameras.
            The actual frame rate may vary slightly due to dropped data, synchronization variation
            between devices, clock accuracy, or if the camera exposure priority mode causes
            reduced frame rate.
            </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.FPS.FPS5">
            <summary>
            5 Frames per second.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.FPS.FPS15">
            <summary>
            15 Frames per second.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.FPS.FPS30">
            <summary>
            30 Frames per second.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.HardwareVersion">
            <summary>
            The hardware version information.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.HardwareVersion.RGB">
            <summary>
            Gets or sets the color camera firmware version.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.HardwareVersion.Depth">
            <summary>
            Gets or sets the depth camera firmware version.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.HardwareVersion.Audio">
            <summary>
            Gets or sets the audio device firmware version.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.HardwareVersion.DepthSensor">
            <summary>
            Gets or sets the depth sensor firmware version.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.HardwareVersion.FirmwareBuild">
            <summary>
            Gets or sets the build type.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.HardwareVersion.FirmwareSignature">
            <summary>
            Gets or sets the firmware signature.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.Image">
            <summary>
            An Azure Kinect Image referencing its buffer and metadata.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.#ctor(Microsoft.Azure.Kinect.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Image"/> class.
            </summary>
            <param name="format">The pixel format of the image. Must be a format with a constant pixel size.</param>
            <param name="widthPixels">Width of the image in pixels.</param>
            <param name="heightPixels">Height of the image in pixels.</param>
            <param name="strideBytes">Stride of the image in bytes. Must be as large as the width times the size of a pixel.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.#ctor(Microsoft.Azure.Kinect.Sensor.ImageFormat,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Image"/> class.
            </summary>
            <param name="format">The pixel format of the image. Must be a format with a constant pixel size.</param>
            <param name="widthPixels">Width of the image in pixels.</param>
            <param name="heightPixels">Height of the image in pixels.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.#ctor(Microsoft.Azure.Kinect.Sensor.NativeMethods.k4a_image_t)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Image"/> class.
            </summary>
            <param name="handle">Handle to initialize the image from</param>
            <remarks>The handle will be owned by the new image.</remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.Finalize">
            <summary>
            Finalizes an instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Image"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.Memory">
            <summary>
            Gets the Memory containing the image data.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.Exposure">
            <summary>
            Gets or sets the image exposure time.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.Format">
            <summary>
            Gets the image pixel format.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.HeightPixels">
            <summary>
            Gets the image height in pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.WidthPixels">
            <summary>
            Gets the image width in pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.StrideBytes">
            <summary>
            Gets the image stride in bytes.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.Size">
            <summary>
            Gets the image buffer size in bytes.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.Timestamp">
            <summary>
            Gets or sets the image timestamp in the device's clock.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.ISOSpeed">
            <summary>
            Gets or sets the ISO speed.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Image.WhiteBalance">
            <summary>
            Gets or sets the white balance.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.GetPixels``1">
            <summary>
            Gets the pixels of the image.
            </summary>
            <typeparam name="TPixel">The type of the pixel.</typeparam>
            <remarks>If the image pixels are not in contiguous memory, this method will throw an exception.</remarks>
            <returns>The contigous memory of the image pixels.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.GetPixels``1(System.Int32)">
            <summary>
            Gets the pixels of the image.
            </summary>
            <typeparam name="TPixel">The type of the pixel.</typeparam>
            <param name="row">The row of pixels to get.</param>
            <returns>The contigous memory of the image pixel row.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.GetPixel``1(System.Int32,System.Int32)">
            <summary>
            Gets a pixel value in the image.
            </summary>
            <typeparam name="TPixel">The type of the pixel.</typeparam>
            <param name="row">The image row.</param>
            <param name="col">The image column.</param>
            <returns>The pixel value at the row and column.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.SetPixel``1(System.Int32,System.Int32,``0)">
            <summary>
            Sets a pixel value in the image.
            </summary>
            <typeparam name="TPixel">The type of the pixel.</typeparam>
            <param name="row">The image row.</param>
            <param name="col">The image column.</param>
            <param name="pixel">The value of the pixel.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.Reference">
            <summary>
            Creates a duplicate reference to the same Image.
            </summary>
            <returns>A new Image object representing the same data.</returns>
            <remarks>Creating a reference to the same image does not copy the image, but
            creates two managed objects representing the same image data. Each object
            must be independently disposed. The lifetime of the underlying image data
            will be equal or greater than all of the referenced image objects.</remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.GetUnsafeBuffer">
             <summary>
             Gets a native pointer to the underlying memory.
             </summary>
             <remarks>
             This property may only be accessed by unsafe code.
            
             This returns an unsafe pointer to the image's memory. It is important that the
             caller ensures the Image is not Disposed or garbage collected while this pointer is
             in use, since it may become invalid when the Image is disposed or finalized.
            
             If this method needs to be used in a context where the caller cannot garantee that the
             Image will be disposed by another thread, the caller can call <see cref="M:Microsoft.Azure.Kinect.Sensor.Image.Reference"/>
             to create a duplicate reference to the Image which can be disposed separately.
            
             For safe buffer access <see cref="P:Microsoft.Azure.Kinect.Sensor.Image.Memory"/>.
             </remarks>
             <returns>A pointer to the native buffer.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.FlushMemory">
            <summary>
            Flush the managed cache of native memory to the native buffer.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.InvalidateMemory">
            <summary>
            Invalidate the managed cache of native memory by reading from the native buffer.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.DangerousGetHandle">
            <summary>
            Gets the native handle.
            </summary>
            <returns>The native handle that is wrapped by this image.</returns>
            <remarks>The function is dangerous because there is no guarantee that the
            handle will not be disposed once it is retrieved. This should only be called
            by code that can ensure that the Image object will not be disposed on another
            thread.</remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.NativeEquals(Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Checks two Images to determine if they represent the same native image object.
            </summary>
            <param name="other">Another Image to compare against.</param>
            <returns>true if the Images represent the same native k4a_image_t.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Image.Dispose(System.Boolean)">
            <summary>
            Disposes the resources held by the image.
            </summary>
            <param name="disposing">True if called by IDisposable.Disppose, false when called by a finalizer.</param>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.ImageFormat">
            <summary>
            Image format.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.ColorMJPG">
             <summary>
             Color image type MJPG.
             </summary>
             <remarks>
             The buffer for each image is encoded as a JPEG and can be decoded by a JPEG decoder.
            
             Because the image is compressed, the Stride property of the Image is not applicable.
            
             Each MJPG encoded image in a stream may be of differing size depending on the compression efficiency.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.ColorNV12">
             <summary>
             Color image type NV12.
             </summary>
             <remarks>
             NV12 images separate the luminance and chroma data such that all the luminance is at the beginning
             of the buffer, and the chroma lines follow immediately after.
            
             Stride indicates the length of each line in bytes and should be used to determine the start location
             of each line of the image in memory. Chroma has half as many lines of height and half the width in
             pixels of the luminance. Each chroma line has the same width in bytes as a luminance line.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.ColorYUY2">
             <summary>
             Color image type YUY2.
             </summary>
             <remarks>
             YUY2 stores chroma and luminance data in interleaved pixels.
            
             Stride indicates the length of each line in bytes and should be used to determine the start location
             of each line of the image in memory.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.ColorBGRA32">
             <summary>
             Color image type BGRA32.
             </summary>
             <remarks>
             Each pixel of BGRA32 data is four bytes. The first three bytes represent Blue, Green, and Red data.
             The fourth byte is the alpha channel and is unused in the Azure Kinect APIs.
            
             Stride indicates the length of each line in bytes and should be used to determine the start location
             of each line of the image in memory.
            
             The Azure Kinect device does not natively capture in this format. Requesting images of this format
             requires additional computation in the API.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.Depth16">
             <summary>
             Depth image type DEPTH16.
             </summary>
             <remarks>
             Each pixel of DEPTH16 data is two bytes of little endian unsigned depth data. The unit of the data
             is in millimeters from the origin of the camera.
            
             Stride indicates the length of each line in bytes and should be used to determine the start location
             of each line of the image in memory.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.IR16">
             <summary>
             Image type IR16.
             </summary>
             <remarks>
             Each pixel of IR16 data is two bytes of little endian unsigned depth data. The value of the data
             represents brightness.
            
             This format represents infrared light and is captured by the depth camera. Stride indicates the
             length of each line in bytes and should be used to determine the start location of each line of
             the image in memory.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.Custom8">
             <summary>
             Single channel image type CUSTOM8.
             </summary>
             <remarks>
             Each pixel of CUSTOM8 is a single channel one byte of unsigned data.
            
             Stride indicates the length of each line in bytes and should be used to determine the start
             location of each line of the image in memory.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.Custom16">
             <summary>
             Single channel image type CUSTOM16.
             </summary>
             <remarks>
             Each pixel of CUSTOM16 is a single channel two bytes of little endian unsigned data.
            
             Stride indicates the length of each line in bytes and should be used to determine the start 
             location of each line of the image in memory.
             </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.ImageFormat.Custom">
             <summary>
             Custom image format.
             </summary>
             <remarks>
             Used in conjunction with user created images or images packing non-standard data.
            
             See the originator of the custom formatted image for information on how to interpret the data. 
             </remarks>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.ImuSample">
            <summary>
            IMU sample.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.ImuSample.Temperature">
            <summary>
            Gets or sets temperature reading of this sample (Celcius).
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.ImuSample.AccelerometerSample">
            <summary>
            Gets or sets accelerometer reading of this sample (meters per second squared).
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.ImuSample.AccelerometerTimestampInUsec">
            <summary>
            Gets or sets timestamp of the accerometer in microseconds.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.ImuSample.GyroSample">
            <summary>
            Gets or sets gyroscope sample in radians per second.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.ImuSample.GyroTimestampInUsec">
            <summary>
            Gets or sets timestamp of the gyroscope in microseconds.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.LargeArrayPool">
             <summary>
             An array pool implementation for large arrays.
             </summary>
             <remarks>
             This ArrayPool allocates and re-uses large arrays to reduce the overhead of
             zero-ing out the buffers and allocating from the managed heap.
            
             Unused arrays are held by weak references and may be garbage collected.
             </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.LargeArrayPool.Rent(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.LargeArrayPool.Return(System.Byte[],System.Boolean)">
            <inheritdoc/>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.Logger">
            <summary>
            The Azure Kinect logging system. Enables access to the debug messages from the Azure Kinect device.
            </summary>
        </member>
        <member name="E:Microsoft.Azure.Kinect.Sensor.Logger.LogMessage">
            <summary>
            Occurs when the Azure Kinect Sensor SDK delivers a debug message.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Logger.Initialized">
            <summary>
            Gets a value indicating whether the <see cref="T:Microsoft.Azure.Kinect.Sensor.Logger"/> class has been initialized and connected to the Azure Kinect Sensor SDK.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Logger.Initialize">
            <summary>
            Initializes the <see cref="T:Microsoft.Azure.Kinect.Sensor.Logger"/> class to begin receiving messages from the Azure Kinect Sensor SDK.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.LogLevel">
            <summary>
            Verbosity levels of debug messaging.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.LogLevel.Critical">
            <summary>
            The most severe level of debug messaging.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.LogLevel.Error">
            <summary>
            The second most severe level of debug messaging.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.LogLevel.Warning">
            <summary>
            The third most severe level of debug messaging.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.LogLevel.Information">
            <summary>
            The second least severe level of debug messaging.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.LogLevel.Trace">
            <summary>
            The lest severe level of debug messaging. This is the most verbose messaging possible.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.LogLevel.Off">
            <summary>
            No logging is performed.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.Native.NativeReferenceAttribute">
            <summary>
            Attribute indicating the native equivalent.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Native.NativeReferenceAttribute.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Native.NativeReferenceAttribute"/> class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Native.NativeReferenceAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Native.NativeReferenceAttribute"/> class with the specified name.
            </summary>
            <param name="referenceName">The name of the native function, handle, enumeration, callback, or structure entity that is being referenced.</param>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Native.NativeReferenceAttribute.ReferenceName">
            <summary>
            Gets the name of the native function, handle, enumeration, callback, or structure entity that is being referenced.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.Short3">
            <summary>
            A value representing a vector of 3 shorts.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Short3.#ctor(System.Int16,System.Int16,System.Int16)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Short3"/> struct.
            </summary>
            <param name="x">X value of the vector.</param>
            <param name="y">Y value of the vector.</param>
            <param name="z">Z value of the vector.</param>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Short3.X">
            <summary>
            Gets or sets the X component of the vector.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Short3.Y">
            <summary>
            Gets or sets the Y component of the vector.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.Kinect.Sensor.Short3.Z">
            <summary>
            Gets or sets the Z component of the vector.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Short3.op_Equality(Microsoft.Azure.Kinect.Sensor.Short3,Microsoft.Azure.Kinect.Sensor.Short3)">
            <summary>
            Compares two Short3 values for equality.
            </summary>
            <param name="left">The first Short3 to compare.</param>
            <param name="right">The second Shrot3 to compare.</param>
            <returns>True if the values are equal.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Short3.op_Inequality(Microsoft.Azure.Kinect.Sensor.Short3,Microsoft.Azure.Kinect.Sensor.Short3)">
            <summary>
            Compares two Short3 values for inequality.
            </summary>
            <param name="left">The first Short3 to compare.</param>
            <param name="right">The second Shrot3 to compare.</param>
            <returns>True if the values are not equal.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Short3.Equals(System.Object)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Short3.GetHashCode">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Short3.Equals(Microsoft.Azure.Kinect.Sensor.Short3)">
            <inheritdoc/>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.Transformation">
            <summary>
            Class that allows the calibrated transformation of Azure Kinect Images.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.#ctor(Microsoft.Azure.Kinect.Sensor.Calibration)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Azure.Kinect.Sensor.Transformation"/> class.
            </summary>
            <param name="calibration">Calibration to use for transformation operations.</param>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.DepthImageToColorCamera(Microsoft.Azure.Kinect.Sensor.Capture)">
            <summary>
            Transforms an Image from the depth camera perspective to the color camera perspective.
            </summary>
            <param name="capture">Capture with the depth image.</param>
            <returns>A depth image transformed in to the color camera perspective.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.DepthImageToColorCamera(Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Transforms an Image from the depth camera perspective to the color camera perspective.
            </summary>
            <param name="depth">The depth image to transform.</param>
            <returns>A depth image transformed in to the color camera perspective.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.DepthImageToColorCamera(Microsoft.Azure.Kinect.Sensor.Capture,Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Transforms an Image from the depth camera perspective to the color camera perspective.
            </summary>
            <param name="capture">Capture with the depth image.</param>
            <param name="transformed">An Image to hold the output.</param>
            <remarks>
            The <paramref name="transformed"/> Image must be of the resolution of the color camera, and
            of the pixel format of the depth image.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.DepthImageToColorCamera(Microsoft.Azure.Kinect.Sensor.Image,Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Transforms an Image from the depth camera perspective to the color camera perspective.
            </summary>
            <param name="depth">Depth image to transform.</param>
            <param name="transformed">An Image to hold the output.</param>
            <remarks>
            The <paramref name="transformed"/> Image must be of the resolution of the color camera, and
            of the pixel format of the depth image.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.ColorImageToDepthCamera(Microsoft.Azure.Kinect.Sensor.Capture)">
            <summary>
            Transforms an Image from the color camera perspective to the depth camera perspective.
            </summary>
            <param name="capture">Capture containing depth and color images.</param>
            <returns>A color image in the perspective of the depth camera.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.ColorImageToDepthCamera(Microsoft.Azure.Kinect.Sensor.Image,Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Transforms an Image from the color camera perspective to the depth camera perspective.
            </summary>
            <param name="depth">Depth map of the space the color image is being transformed in to.</param>
            <param name="color">Color image to transform in to the depth space.</param>
            <returns>A color image in the perspective of the depth camera.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.ColorImageToDepthCamera(Microsoft.Azure.Kinect.Sensor.Capture,Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Transforms an Image from the color camera perspective to the depth camera perspective.
            </summary>
            <param name="capture">Capture containing depth and color images.</param>
            <param name="transformed">An Image to hold the output.</param>
            <remarks>
            The <paramref name="transformed"/> Image must be of the resolution of the depth camera, and
            of the pixel format of the color image.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.ColorImageToDepthCamera(Microsoft.Azure.Kinect.Sensor.Image,Microsoft.Azure.Kinect.Sensor.Image,Microsoft.Azure.Kinect.Sensor.Image)">
            <summary>
            Transforms an Image from the color camera perspective to the depth camera perspective.
            </summary>
            <param name="depth">Depth map of the space the color image is being transformed in to.</param>
            <param name="color">Color image to transform in to the depth space.</param>
            <param name="transformed">An Image to hold the output.</param>
            <remarks>
            The <paramref name="transformed"/> Image must be of the resolution of the depth camera, and
            of the pixel format of the color image.
            </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.DepthImageToPointCloud(Microsoft.Azure.Kinect.Sensor.Image,Microsoft.Azure.Kinect.Sensor.CalibrationDeviceType)">
             <summary>
             Creates a point cloud from a depth image.
             </summary>
             <param name="depth">The depth map to generate the point cloud from.</param>
             <param name="camera">The perspective the depth map is from.</param>
             <remarks>
             If the depth map is from the original depth perspecive, <paramref name="camera"/> should be Depth. If it has
             been transformed to the color camera perspective, <paramref name="camera"/> should be Color.
            
             The returned image will be of format Custom. Each pixel will be an XYZ set of 16 bit values,
             therefore its stride must is 2(bytes) * 3(x,y,z) * width of the <paramref name="depth"/> image in pixels.
             </remarks>
             <returns>A point cloud image.</returns>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.DepthImageToPointCloud(Microsoft.Azure.Kinect.Sensor.Image,Microsoft.Azure.Kinect.Sensor.Image,Microsoft.Azure.Kinect.Sensor.CalibrationDeviceType)">
             <summary>
             Creates a point cloud from a depth image.
             </summary>
             <param name="depth">The depth map to generate the point cloud from.</param>
             <param name="pointCloud">The image to store the output point cloud.</param>
             <param name="camera">The perspective the depth map is from.</param>
             <remarks>
             If the depth map is from the original depth perspecive, <paramref name="camera"/> should be Depth. If it has
             been transformed to the color camera perspective, <paramref name="camera"/> should be Color.
            
             The <paramref name="pointCloud"/> image must be of format Custom. Each pixel will be an XYZ set of 16 bit values,
             therefore its stride must be 2(bytes) * 3(x,y,z) * width of the <paramref name="depth"/> image in pixels.
             </remarks>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Azure.Kinect.Sensor.Transformation.Dispose(System.Boolean)">
            <summary>
            Implements the dispose operation.
            </summary>
            <param name="disposing">True if called from Dispose.</param>
        </member>
        <member name="T:Microsoft.Azure.Kinect.Sensor.WiredSyncMode">
            <summary>
            Synchronization mode when connecting two or more devices together.
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.WiredSyncMode.Standalone">
            <summary>
            Neither 'Sync In' or 'Sync Out' connections are used. 
            </summary>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.WiredSyncMode.Master">
            <summary>
            The 'Sync Out' jack is enabled and synchronization data it driven out the connected wire.
            </summary>
            <remarks>
            While in master mode the color camera must be enabled as part of the multi device sync
            signalling logic. Even if the color image is not needed, the color camera must be running.
            </remarks>
        </member>
        <member name="F:Microsoft.Azure.Kinect.Sensor.WiredSyncMode.Subordinate">
            <summary>
            The 'Sync In' jack is used for synchronization and 'Sync Out' is driven for the next device in the chain.
            </summary>
            <remarks>
            'Sync Out' is a mirror of 'Sync In' for this mode. 
            </remarks>
        </member>
    </members>
</doc>
